# Training configuration for custom interpolation experiment

data:
  # Paths to your specific data files
  coarse_file: '/home/qg7/Vertex/dataset/002-Re-148_3-AC-beta-10000-Helios/180-60/cropped.e'
  fine_file: '/home/qg7/Vertex/dataset/002-Re-148_3-AC-beta-10000-Helios/360-120/cropped.e'
  
  # Time offset (Fine[N] = Interp[N+54])
  time_offset: 54
  
  # Caching
  use_cache: true
  cache_dir: './cache'

model:
  type: 'gnn'                    # Options: gnn, encoder_decoder, mlp
  hidden_channels: 128
  num_layers: 4
  dropout: 0.1
  k_neighbors: 8                 # Number of neighbors for graph construction

training:
  # Optional: device selection. Examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1'.
  # If omitted/null: auto-select (cuda:0 if available else cpu).
  device: null
  batch_size: 1                  # Graph data typically uses batch_size=1
  learning_rate: 0.001
  weight_decay: 0.00001
  num_epochs: 100
  save_every: 10
  output_dir: './outputs'
  validation_split: 0.2          # Use 20% of timesteps for validation

  # -----------------------------
  # Data loss configuration
  # -----------------------------
  # Choose which loss is optimized during training:
  #   - 'mse'   (weighted L2)
  #   - 'huber' (weighted SmoothL1)
  data_loss_type: 'mse'
  # Huber transition point (beta). Only used when data_loss_type='huber'.
  data_loss_huber_delta: 1.0
  # Per-output-channel weights. For 3-output training (vx, vy, p), a common
  # choice to emphasize pressure is [1.0, 1.0, 5.0] or higher.
  # If omitted, train_custom.py defaults to [1.0, 1.0, 5.0] (vx, vy, p).
  data_loss_channel_weights: [1.0, 1.0, 5.0]

  # Optional: explicitly control which fields are used as inputs/outputs.
  # Assumes stacked field order [vx, vy, p, T].
  input_feature_indices: [0, 1, 2]
  output_feature_indices: [0, 1, 2]

# Note: The training script will automatically handle linear interpolation
# from coarse to fine mesh during data loading
